# å¦‚ä½•ä¸ºè‡ªå·±è®­ç»ƒçš„ VQ-VAE é‡æ–°ç”Ÿæˆæ•°æ®é›†

## ğŸ“Œ é—®é¢˜è¯´æ˜

å¦‚æœä½ è‡ªå·±è®­ç»ƒäº†ä¸€ä¸ªæ–°çš„ VQ-VAE æ¨¡å‹ï¼Œéœ€è¦é‡æ–°ä¸ºæ•°æ®é›†ç”Ÿæˆé‡åŒ–ç´¢å¼•ï¼ˆVQ indicesï¼‰ï¼Œå› ä¸ºï¼š

1. **ç°æœ‰æ•°æ®é›†å·²åŒ…å«é¢„è®¡ç®—çš„ VQ ç´¢å¼•**ï¼šåœ¨æ¯ä¸ªåœºæ™¯ç›®å½•çš„ `models_info.pkl` æ–‡ä»¶ä¸­å­˜å‚¨äº†ç‰©ä½“çš„é‡åŒ–ç´¢å¼•
2. **ç´¢å¼•ä¾èµ–äºç‰¹å®šçš„ VQ-VAE æ¨¡å‹**ï¼šä¸åŒçš„ VQ-VAE æ¨¡å‹ï¼ˆä¸åŒçš„ç æœ¬ï¼‰ä¼šäº§ç”Ÿä¸åŒçš„é‡åŒ–ç´¢å¼•
3. **åç»­è®­ç»ƒéœ€è¦è¿™äº›ç´¢å¼•**ï¼šSemantic Graph Prior å’Œ Layout Decoder éƒ½ä¾èµ–è¿™äº›é¢„è®¡ç®—çš„ç´¢å¼•

## ğŸ” æ•°æ®é›†ç»“æ„

æ¯ä¸ªåœºæ™¯ç›®å½•åŒ…å«ï¼š
```
threed_front_bedroom/
â””â”€â”€ <scene_id>/
    â”œâ”€â”€ boxes.npz                          # è¾¹ç•Œæ¡†æ•°æ®
    â”œâ”€â”€ descriptions.pkl                   # ChatGPT ç”Ÿæˆçš„æ–‡æœ¬æè¿°
    â”œâ”€â”€ models_info.pkl                    # â­ ç‰©ä½“ä¿¡æ¯ï¼ˆåŒ…å« VQ ç´¢å¼•ï¼‰
    â”œâ”€â”€ openshape_pointbert_vitg14.npy    # OpenShape ç‰¹å¾
    â”œâ”€â”€ relations.npy                      # ç‰©ä½“å…³ç³»
    â””â”€â”€ ...
```

`models_info.pkl` ç»“æ„ï¼ˆåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªç‰©ä½“ï¼‰ï¼š
```python
[
    {
        "model_jid": "xxx",                    # ç‰©ä½“ ID
        "category": "bed",                      # ç‰©ä½“ç±»åˆ«
        "objfeat_vq_indices": [12, 45, 3, 28], # â­ VQ é‡åŒ–ç´¢å¼•ï¼ˆ4ä¸ªï¼‰
        ...
    },
    ...
]
```

## ğŸ› ï¸ é‡æ–°ç”Ÿæˆ VQ ç´¢å¼•çš„æ­¥éª¤

### æ­¥éª¤ 1: å‡†å¤‡ä½ çš„ VQ-VAE æ¨¡å‹

ç¡®ä¿ä½ å·²ç»è®­ç»ƒå¥½äº† VQ-VAE æ¨¡å‹å¹¶ä¿å­˜äº†æ£€æŸ¥ç‚¹ï¼š
```bash
# è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¿å­˜åœ¨
out/<your_vqvae_tag>/checkpoints/epoch_XXXXX.pth
```

### æ­¥éª¤ 2: åˆ›å»ºç´¢å¼•ç”Ÿæˆè„šæœ¬

åˆ›å»ºä¸€ä¸ª Python è„šæœ¬æ¥é‡æ–°ç”Ÿæˆæ‰€æœ‰åœºæ™¯çš„ VQ ç´¢å¼•ï¼š

```python
# regenerate_vq_indices.py
import os
import pickle
import argparse
from tqdm import tqdm
import numpy as np
import torch

from src.models import model_from_config
from src.utils import load_config, load_checkpoints


def regenerate_indices_for_scene(scene_dir, vqvae_model, device):
    """ä¸ºå•ä¸ªåœºæ™¯é‡æ–°ç”Ÿæˆ VQ ç´¢å¼•"""
    models_info_path = os.path.join(scene_dir, "models_info.pkl")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(models_info_path):
        return False
    
    # åŠ è½½ç°æœ‰çš„ models_info
    with open(models_info_path, "rb") as f:
        models_info = pickle.load(f)
    
    # åŠ è½½ OpenShape ç‰¹å¾
    openshape_feat_path = os.path.join(scene_dir, "openshape_pointbert_vitg14.npy")
    if not os.path.exists(openshape_feat_path):
        return False
    
    openshape_feats = np.load(openshape_feat_path)  # (N, 1280)
    
    # ä½¿ç”¨ VQ-VAE ç¼–ç ä¸ºç´¢å¼•
    with torch.no_grad():
        # å½’ä¸€åŒ–ç‰¹å¾åˆ° [-1, 1]ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶çš„è¾¹ç•Œï¼‰
        # æ³¨æ„ï¼šéœ€è¦ä½¿ç”¨ä¸è®­ç»ƒ VQ-VAE æ—¶ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•°
        feats_normalized = torch.from_numpy(openshape_feats).float().to(device)
        
        # ç¼–ç ä¸º VQ ç´¢å¼•
        vq_indices = vqvae_model.quantize_to_indices(feats_normalized)  # (N, K)
        vq_indices = vq_indices.cpu().numpy()
    
    # æ›´æ–° models_info ä¸­çš„ç´¢å¼•
    assert len(models_info) == len(vq_indices), \
        f"ç‰©ä½“æ•°é‡ä¸åŒ¹é…: {len(models_info)} vs {len(vq_indices)}"
    
    for i, model_info in enumerate(models_info):
        model_info["objfeat_vq_indices"] = vq_indices[i].tolist()
    
    # ä¿å­˜æ›´æ–°åçš„ models_info
    with open(models_info_path, "wb") as f:
        pickle.dump(models_info, f)
    
    return True


def main():
    parser = argparse.ArgumentParser(
        description="é‡æ–°ç”Ÿæˆæ•°æ®é›†çš„ VQ ç´¢å¼•"
    )
    parser.add_argument(
        "--vqvae_config",
        type=str,
        required=True,
        help="VQ-VAE é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--vqvae_tag",
        type=str,
        required=True,
        help="VQ-VAE å®éªŒæ ‡ç­¾"
    )
    parser.add_argument(
        "--vqvae_epoch",
        type=int,
        default=-1,
        help="VQ-VAE checkpoint epochï¼ˆ-1 è¡¨ç¤ºæœ€æ–°ï¼‰"
    )
    parser.add_argument(
        "--dataset_dir",
        type=str,
        required=True,
        help="æ•°æ®é›†ç›®å½•ï¼ˆå¦‚ dataset/InstructScene/threed_front_bedroomï¼‰"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="0",
        help="CUDA è®¾å¤‡"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(f"cuda:{args.device}" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # åŠ è½½ VQ-VAE æ¨¡å‹
    print(f"åŠ è½½ VQ-VAE æ¨¡å‹: {args.vqvae_tag}")
    config = load_config(args.vqvae_config)
    vqvae_model = model_from_config(config)
    vqvae_model = vqvae_model.to(device)
    vqvae_model.eval()
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    ckpt_path = os.path.join("out", args.vqvae_tag, "checkpoints")
    vqvae_model = load_checkpoints(vqvae_model, ckpt_path, args.vqvae_epoch, device)
    print(f"å·²åŠ è½½ checkpoint\n")
    
    # éå†æ‰€æœ‰åœºæ™¯ç›®å½•
    scene_dirs = [
        os.path.join(args.dataset_dir, d)
        for d in os.listdir(args.dataset_dir)
        if os.path.isdir(os.path.join(args.dataset_dir, d))
        and not d.startswith("_")  # è·³è¿‡æ¸²æŸ“ç›®å½•
    ]
    
    print(f"æ‰¾åˆ° {len(scene_dirs)} ä¸ªåœºæ™¯")
    print("å¼€å§‹é‡æ–°ç”Ÿæˆ VQ ç´¢å¼•...\n")
    
    success_count = 0
    for scene_dir in tqdm(scene_dirs, desc="å¤„ç†åœºæ™¯"):
        if regenerate_indices_for_scene(scene_dir, vqvae_model, device):
            success_count += 1
    
    print(f"\nå®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(scene_dirs)} ä¸ªåœºæ™¯")


if __name__ == "__main__":
    main()
```

### æ­¥éª¤ 3: è¿è¡Œè„šæœ¬é‡æ–°ç”Ÿæˆç´¢å¼•

ä¸ºæ¯ä¸ªæˆ¿é—´ç±»å‹è¿è¡Œè„šæœ¬ï¼š

```bash
# å§å®¤
python -m src.regenerate_vq_indices \
  --vqvae_config configs/threedfront_objfeat_vqvae.yaml \
  --vqvae_tag <your_vqvae_tag> \
  --vqvae_epoch -1 \
  --dataset_dir dataset/InstructScene/threed_front_bedroom \
  --device 0

# é¤å…
python -m src.regenerate_vq_indices \
  --vqvae_config configs/threedfront_objfeat_vqvae.yaml \
  --vqvae_tag <your_vqvae_tag> \
  --vqvae_epoch -1 \
  --dataset_dir dataset/InstructScene/threed_front_diningroom \
  --device 0

# å®¢å…
python -m src.regenerate_vq_indices \
  --vqvae_config configs/threedfront_objfeat_vqvae.yaml \
  --vqvae_tag <your_vqvae_tag> \
  --vqvae_epoch -1 \
  --dataset_dir dataset/InstructScene/threed_front_livingroom \
  --device 0
```

### æ­¥éª¤ 4: éªŒè¯ç”Ÿæˆçš„ç´¢å¼•

è¿è¡Œä¸€ä¸ªç®€å•çš„éªŒè¯è„šæœ¬ï¼š

```python
# verify_indices.py
import os
import pickle
import numpy as np

def verify_scene(scene_dir):
    """éªŒè¯å•ä¸ªåœºæ™¯çš„ VQ ç´¢å¼•"""
    models_info_path = os.path.join(scene_dir, "models_info.pkl")
    
    with open(models_info_path, "rb") as f:
        models_info = pickle.load(f)
    
    for i, model_info in enumerate(models_info):
        if "objfeat_vq_indices" not in model_info:
            print(f"âŒ ç¼ºå°‘ VQ ç´¢å¼•: {scene_dir}, ç‰©ä½“ {i}")
            return False
        
        indices = model_info["objfeat_vq_indices"]
        if not isinstance(indices, (list, np.ndarray)):
            print(f"âŒ ç´¢å¼•æ ¼å¼é”™è¯¯: {scene_dir}, ç‰©ä½“ {i}")
            return False
        
        if len(indices) != 4:  # åº”è¯¥æœ‰ 4 ä¸ªç´¢å¼•
            print(f"âŒ ç´¢å¼•æ•°é‡é”™è¯¯: {scene_dir}, ç‰©ä½“ {i}, æ•°é‡: {len(indices)}")
            return False
        
        if not all(0 <= idx < 64 for idx in indices):  # ç´¢å¼•åº”è¯¥åœ¨ [0, 64) èŒƒå›´å†…
            print(f"âŒ ç´¢å¼•å€¼è¶…å‡ºèŒƒå›´: {scene_dir}, ç‰©ä½“ {i}, ç´¢å¼•: {indices}")
            return False
    
    return True

# éªŒè¯æ‰€æœ‰åœºæ™¯
dataset_dir = "dataset/InstructScene/threed_front_bedroom"
scene_dirs = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]

success = 0
for scene_dir in scene_dirs:
    if verify_scene(os.path.join(dataset_dir, scene_dir)):
        success += 1

print(f"éªŒè¯å®Œæˆ: {success}/{len(scene_dirs)} ä¸ªåœºæ™¯é€šè¿‡")
```

### æ­¥éª¤ 5: ä½¿ç”¨æ–°ç´¢å¼•è®­ç»ƒåç»­æ¨¡å‹

ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨æ›´æ–°åçš„æ•°æ®é›†è®­ç»ƒ Semantic Graph Prior å’Œ Layout Decoderï¼š

```bash
# è®­ç»ƒ Layout Decoder
bash scripts/train_sg2sc_objfeat.sh bedroom bedroom_sg2scdiffusion_objfeat 0 <your_vqvae_tag>

# è®­ç»ƒ Semantic Graph Prior
bash scripts/train_sg_vq_objfeat.sh bedroom bedroom_sgdiffusion_vq_objfeat 0
```

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

### 1. ç‰¹å¾å½’ä¸€åŒ–
ç¡®ä¿ä½¿ç”¨ä¸è®­ç»ƒ VQ-VAE æ—¶**ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•°**ï¼š
```python
# å¦‚æœè®­ç»ƒæ—¶ä½¿ç”¨äº†ç‰¹å®šçš„ min/max å½’ä¸€åŒ–
bounds_path = os.path.join("out", vqvae_tag, "objfeat_bounds.pkl")
with open(bounds_path, "rb") as f:
    bounds = pickle.load(f)

feats_min, feats_max = bounds["min"], bounds["max"]
feats_normalized = 2 * (feats - feats_min) / (feats_max - feats_min) - 1
```

### 2. ç æœ¬å¤§å°
å¦‚æœä½ çš„ VQ-VAE ä½¿ç”¨äº†ä¸åŒçš„ç æœ¬å¤§å°ï¼ˆé»˜è®¤æ˜¯ 64ï¼‰ï¼Œéœ€è¦ï¼š
- æ›´æ–°è„šæœ¬ä¸­çš„ç´¢å¼•èŒƒå›´æ£€æŸ¥
- æ›´æ–°åç»­æ¨¡å‹é…ç½®ä¸­çš„ `num_objfeat_embeds` å‚æ•°

### 3. Token æ•°é‡
å¦‚æœä½ çš„ VQ-VAE ä½¿ç”¨äº†ä¸åŒæ•°é‡çš„ tokensï¼ˆé»˜è®¤æ˜¯ 4ï¼‰ï¼Œéœ€è¦ï¼š
- æ›´æ–°è„šæœ¬ä¸­çš„ç´¢å¼•æ•°é‡æ£€æŸ¥
- æ›´æ–°åç»­æ¨¡å‹é…ç½®ä¸­ç›¸å…³çš„ç»´åº¦å‚æ•°

### 4. å¤‡ä»½åŸå§‹æ•°æ®
åœ¨è¿è¡Œé‡æ–°ç”Ÿæˆè„šæœ¬ä¹‹å‰ï¼Œ**å¼ºçƒˆå»ºè®®å¤‡ä»½åŸå§‹æ•°æ®é›†**ï¼š
```bash
# å¤‡ä»½æ•´ä¸ªæ•°æ®é›†ç›®å½•
cp -r dataset/InstructScene dataset/InstructScene_backup
```

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨
**é”™è¯¯**: `FileNotFoundError: openshape_pointbert_vitg14.npy`

**è§£å†³æ–¹æ¡ˆ**: ç¡®ä¿åœºæ™¯ç›®å½•ä¸­åŒ…å« OpenShape ç‰¹å¾æ–‡ä»¶ã€‚å¦‚æœç¼ºå¤±ï¼Œéœ€è¦å…ˆæå–ç‰¹å¾ã€‚

### é—®é¢˜ 2: ç»´åº¦ä¸åŒ¹é…
**é”™è¯¯**: `RuntimeError: Expected input dimension xxx but got yyy`

**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥ VQ-VAE é…ç½®ä¸­çš„ `kv_dim` å‚æ•°æ˜¯å¦ä¸ç‰¹å¾ç»´åº¦åŒ¹é…ï¼ˆOpenShape ViT-G/14 æ˜¯ 1280ï¼‰ã€‚

### é—®é¢˜ 3: ç´¢å¼•è¶…å‡ºèŒƒå›´
**é”™è¯¯**: ç”Ÿæˆçš„ç´¢å¼•å€¼ > 63

**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥é‡åŒ–å™¨çš„ç æœ¬å¤§å°è®¾ç½®ï¼Œç¡®ä¿ä¸é…ç½®ä¸€è‡´ã€‚

## ğŸ“š ç›¸å…³æ–‡ä»¶

- **VQ-VAE æ¨¡å‹**: `src/models/objfeat_vqvae.py`
- **æ•°æ®åŠ è½½**: `src/data/threed_front_dataset.py`
- **é…ç½®æ–‡ä»¶**: `configs/threedfront_objfeat_vqvae.yaml`
- **ç´¢å¼•ä½¿ç”¨ç¤ºä¾‹**: 
  - `src/models/sg2sc_diffusion.py` (Line 72-96)
  - `src/models/sg_diffusion_vq_objfeat.py` (Line 104)

## ğŸ’¡ è¿›é˜¶ï¼šå¹¶è¡Œå¤„ç†

å¦‚æœæ•°æ®é›†å¾ˆå¤§ï¼Œå¯ä»¥ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿï¼š

```python
from multiprocessing import Pool

def process_scene_wrapper(args):
    scene_dir, vqvae_model, device = args
    return regenerate_indices_for_scene(scene_dir, vqvae_model, device)

# åœ¨ main() å‡½æ•°ä¸­
with Pool(processes=4) as pool:  # ä½¿ç”¨ 4 ä¸ªè¿›ç¨‹
    args_list = [(scene_dir, vqvae_model, device) for scene_dir in scene_dirs]
    results = list(tqdm(
        pool.imap(process_scene_wrapper, args_list),
        total=len(scene_dirs),
        desc="å¤„ç†åœºæ™¯"
    ))
```

## ğŸ“– æ€»ç»“

é‡æ–°ç”Ÿæˆ VQ ç´¢å¼•çš„æ ¸å¿ƒæ­¥éª¤ï¼š
1. âœ… è®­ç»ƒä½ çš„ VQ-VAE æ¨¡å‹
2. âœ… ä½¿ç”¨ `quantize_to_indices()` æ–¹æ³•ç¼–ç ç‰¹å¾
3. âœ… æ›´æ–°æ¯ä¸ªåœºæ™¯çš„ `models_info.pkl` æ–‡ä»¶
4. âœ… éªŒè¯ç´¢å¼•çš„æ­£ç¡®æ€§
5. âœ… ä½¿ç”¨æ›´æ–°åçš„æ•°æ®é›†è®­ç»ƒåç»­æ¨¡å‹

è¿™æ ·å°±å¯ä»¥ç¡®ä¿ä½ çš„æ•´ä¸ªè®­ç»ƒæµç¨‹ä½¿ç”¨ä¸€è‡´çš„ VQ-VAE ç¼–ç ï¼

